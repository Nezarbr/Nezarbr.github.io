{"componentChunkName":"component---src-templates-blog-post-jsx","path":"/blog/my-first-blog/","result":{"data":{"site":{"siteMetadata":{"name":"Nezar Boujida","title":"Nezar Boujida | Data Scientist","description":null,"about":"Hello, I'm Nezar. I'm currently studying Applied Mathematics and Computer Science at Sorbonne University, where I dive into data science, explore datasets, and uncover meaningful patterns to solve real-world problems. I've gained experience as a Data Scientist intern at Datategy and Hiflow, and now I'm working as an Applied Scientist at Launchmetrics. In my free time, I enjoy long-distance running, traveling, and discovering new places, always seeking out new challenges to grow and learn.","author":null,"github":"https://github.com/Nezarbr","linkedin":"https://www.linkedin.com/in/nezar-boujida/"}},"markdownRemark":{"id":"86723165-5a16-532f-8f50-95e835ed5005","excerpt":"Introduction As computing technology advances, modern microprocessors are becoming more powerful, consuming up to 200 watts of power or more. This immense…","html":"<h2>Introduction</h2>\n<p>As computing technology advances, modern microprocessors are becoming more powerful, consuming up to 200 watts of power or more. This immense energy consumption generates significant heat, which, if not managed properly, can degrade the processor’s performance and reliability. To address this, heatsinks are crucial components designed to dissipate this heat, transferring it away from the processor into the heatsink itself, where it can be safely dispersed into the surrounding environment.</p>\n<p>In this research, we focus on simulating the heat transfer dynamics within a CPU heatsink. By parallelizing the simulation process, we aim to efficiently model the heat dissipation behavior across a complex grid structure, allowing for accurate predictions of temperature distributions within the heatsink. Through optimized computational strategies, we explore how to minimize simulation time while maintaining the accuracy of the thermal modeling.</p>\n<p>In this article, we investigate several parallelization methods that distribute the workload across multiple processors, improving efficiency in large-scale simulations of heat transfer in CPU heatsinks.</p>\n<hr>\n<h2>Approach</h2>\n<p>In our study, we implemented a parallelized simulation to model the heat transfer within a CPU heatsink. The simulation’s core principle is to divide the heatsink into a 3D grid of cuboidal cells, each representing a discrete volume of the heatsink. This spatial discretization allows us to track temperature changes in each cell based on heat conduction between neighboring cells over time.</p>\n<p>The key challenge is the computational cost of such simulations, especially when using finer grids for higher accuracy. To overcome this, we employed <strong>parallelization</strong> by dividing the heatsink grid into smaller subdomains, each assigned to a different processor. These processors then handle the computation for their respective subdomains simultaneously, significantly speeding up the simulation.</p>\n<p>We explored two main parallelization techniques:</p>\n<ol>\n<li><strong>1D Slicing (Z-axis slicing)</strong>: In this method, the heatsink is sliced along the Z-axis, and each slice is assigned to a processor. This method offers simplicity but requires careful management of communication between processors, as each slice needs to exchange temperature data with its neighbors to ensure accuracy.</li>\n<li><strong>2D Slicing (Z and Y axes slicing)</strong>: This more complex technique involves slicing the heatsink along both the Z and Y axes, breaking the heatsink into smaller parallelepipeds. Each of these sections is then assigned to a processor. While this approach increases communication overhead, it provides more granular control over the simulation and allows for better scalability in larger systems.</li>\n</ol>\n<p>In both cases, we used <strong>Message Passing Interface (MPI)</strong> to manage communication between processors. For edge cells, where neighboring cells belong to different subdomains, processors exchange temperature data via MPI. To ensure that all processors work in sync, we implemented non-blocking communication techniques, allowing processors to continue computations while waiting for data from neighboring processors, further improving efficiency.</p>\n<p>Additionally, we implemented a <strong>checkpointing</strong> system to periodically save the simulation’s state, enabling the process to resume from the last checkpoint in the event of a failure, ensuring robustness in long simulations.</p>\n<hr>\n<h2>Results</h2>\n<p>Our parallelization strategies produced significant performance improvements, as detailed below:</p>\n<h3>1. <strong>1D Slicing (Z-axis)</strong>:</h3>\n<ul>\n<li>With 12 processors, this method reduced execution time from 760 seconds (sequential execution) to 168 seconds, achieving a speedup of approximately <strong>4.52x</strong>.</li>\n<li>Beyond 20 processors, performance began to degrade due to increased communication overhead between processors, showing that this method is more suited for smaller to medium-sized simulations.</li>\n</ul>\n<div style=\"text-align: center;\">\n    <span class=\"gatsby-resp-image-wrapper\" style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 412px; margin: 0 0 30px;\">\n      <a class=\"gatsby-resp-image-link\" href=\"/static/923470de9ad80e8aa947dfb3aed2af30/9e32a/heatsink_work3.png\" style=\"display: block\" target=\"_blank\" rel=\"noopener\">\n    <span class=\"gatsby-resp-image-background-image\" style=\"padding-bottom: 114.86486486486487%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAXCAYAAAALHW+jAAAACXBIWXMAABYlAAAWJQFJUiTwAAAD10lEQVQ4y32UC1NaRxiG/cudTpuZZqbtxJipk3ZqMrYqXhKKEuSiBRGQq3jXRDSa1hpNq8YiKqgB5Vw45zzZc7ir7eF8s7uw++y7L9+3HYZhYABWa4aumwPqjzk2WsbU5jTm34oOarA2iAjt4gJlexspFEaKRlF2dtCurmhB34WLrzrqu1uQUgl1dxcpkaDs9lB2OCg7nZTHxiiPjlL2eJCSSTHnPVqxeBfeqlB9+xZpYqK60ASMjyMJQNntRrJC9F3jTbjPhzSbRt3fR7++bsCrQE1DSaeRAwGU6SCyAEsCaEFrwHJra27kciHV1EsCLs/NUTnPNxXqK6sQCKIJz5RIpAk2F9fAZXdzA9k8vlBt/i55RfgmqBwfNz3Mn34kE3RyOemFmRj6TBQ5NC3AIqYCDZBUU2hBzU0mJ1HFn6bGk+iSVAOKd7a4zY9rI3S//J6ArZv87z6IRNFDIZSZMGokTMXsC4AF83pFBkyjxxLciLb4916Lh7pBWvoDr7yKI5ugK97Lt/0PcPd1kfW6IBrHCAqlkRo4HkeamYFYkvOgn98iA7wrHVWB9SPvlLI4cosEtNdMVTIW+HGil2/6vmb0l0cce18JcAymhcpYFJJpdn1j9EX6cZylyWuldmBmp0yXM0NnLII9l8YvwCFtk9GTJF2pX3loe4BjoJNDnxNDeLzgGeR5ehhvaY2lkkgds8IsYC0pX+9W8C9I9I6/5ytbhM5EkLHCPNNk8CtveCVU/LQ8zBP3Y15O9GDb8DClZOhfX2Vpu2DBdDOx6wo/HMgEUhKpbfDPleh+sckXA36eLkUY/2Ra8UYANvAUFnBmU0TULfpWFhkKHnB0plm11gI0OF2X8fecYrfnmF5WSG2BJ3bBo8FVvhwJ0LMRw3O9TFCAQ9Imz2bnsYePWcgoyLJGPZ87qgINChmVA4/EbF+O4e59Rj1nRDM68YzBWPiU74aWeeiJMri3yPPUCq5kjmDsmk3/ZbWOm8DqkZWSxvmawklI5S9Xicmn/zDw8wfckSvimwaJjIY9mOOZZwfvfIGpZIkF2yk3fyoNde3XV+3OKR6qZGMy2aDKuj2P48keQ7aPTC1KJDZEvr7TCCQ+ke4/obgio2sGrYzm9WXtUMWqZaFWeJoVao8CsmXDyA+HeANFJqNF0gOnXImMaIdV13fUpTagelPt9b9CbVImF6qw570h1l9g5cUll7MSmqxTr7I7R76tsLWvqTqFLYVsWPgbVLgQqVW5uR/WqOX2i/c+tXBzViG/KiMXKi2wdv/uBf6fWqMFYH1u2fWfwHvV1q65O57fAn4G/Ep9XILJuD4AAAAASUVORK5CYII='); background-size: cover; display: block;\"></span>\n  <img class=\"gatsby-resp-image-image\" alt=\"Driver's Diversity vs. Number of Transfers\" title=\"Driver's Diversity vs. Number of Transfers\" src=\"/static/923470de9ad80e8aa947dfb3aed2af30/9e32a/heatsink_work3.png\" srcset=\"/static/923470de9ad80e8aa947dfb3aed2af30/12f09/heatsink_work3.png 148w,\n/static/923470de9ad80e8aa947dfb3aed2af30/e4a3f/heatsink_work3.png 295w,\n/static/923470de9ad80e8aa947dfb3aed2af30/9e32a/heatsink_work3.png 412w\" sizes=\"(max-width: 412px) 100vw, 412px\" style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\" loading=\"lazy\">\n  </a>\n    </span>\n</div>\n<h3>2. <strong>2D Slicing (Z and Y axes)</strong>:</h3>\n<ul>\n<li>This method performed even better, achieving a speedup of <strong>4.94x</strong> with 32 processors, reducing execution time to 154 seconds.</li>\n<li>With further optimization through non-blocking communication, the execution time decreased to 135 seconds, resulting in a speedup of <strong>5.63x</strong> compared to the sequential code.</li>\n<li>Unlike the 1D approach, 2D slicing showed minimal variance in performance with increasing processors, making it more scalable for larger simulations.</li>\n</ul>\n<div style=\"text-align: center;\">\n    <span class=\"gatsby-resp-image-wrapper\" style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 412px; margin: 0 0 30px;\">\n      <a class=\"gatsby-resp-image-link\" href=\"/static/923470de9ad80e8aa947dfb3aed2af30/9e32a/heatsink_work3.png\" style=\"display: block\" target=\"_blank\" rel=\"noopener\">\n    <span class=\"gatsby-resp-image-background-image\" style=\"padding-bottom: 114.86486486486487%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAXCAYAAAALHW+jAAAACXBIWXMAABYlAAAWJQFJUiTwAAAD10lEQVQ4y32UC1NaRxiG/cudTpuZZqbtxJipk3ZqMrYqXhKKEuSiBRGQq3jXRDSa1hpNq8YiKqgB5Vw45zzZc7ir7eF8s7uw++y7L9+3HYZhYABWa4aumwPqjzk2WsbU5jTm34oOarA2iAjt4gJlexspFEaKRlF2dtCurmhB34WLrzrqu1uQUgl1dxcpkaDs9lB2OCg7nZTHxiiPjlL2eJCSSTHnPVqxeBfeqlB9+xZpYqK60ASMjyMJQNntRrJC9F3jTbjPhzSbRt3fR7++bsCrQE1DSaeRAwGU6SCyAEsCaEFrwHJra27kciHV1EsCLs/NUTnPNxXqK6sQCKIJz5RIpAk2F9fAZXdzA9k8vlBt/i55RfgmqBwfNz3Mn34kE3RyOemFmRj6TBQ5NC3AIqYCDZBUU2hBzU0mJ1HFn6bGk+iSVAOKd7a4zY9rI3S//J6ArZv87z6IRNFDIZSZMGokTMXsC4AF83pFBkyjxxLciLb4916Lh7pBWvoDr7yKI5ugK97Lt/0PcPd1kfW6IBrHCAqlkRo4HkeamYFYkvOgn98iA7wrHVWB9SPvlLI4cosEtNdMVTIW+HGil2/6vmb0l0cce18JcAymhcpYFJJpdn1j9EX6cZylyWuldmBmp0yXM0NnLII9l8YvwCFtk9GTJF2pX3loe4BjoJNDnxNDeLzgGeR5ehhvaY2lkkgds8IsYC0pX+9W8C9I9I6/5ytbhM5EkLHCPNNk8CtveCVU/LQ8zBP3Y15O9GDb8DClZOhfX2Vpu2DBdDOx6wo/HMgEUhKpbfDPleh+sckXA36eLkUY/2Ra8UYANvAUFnBmU0TULfpWFhkKHnB0plm11gI0OF2X8fecYrfnmF5WSG2BJ3bBo8FVvhwJ0LMRw3O9TFCAQ9Imz2bnsYePWcgoyLJGPZ87qgINChmVA4/EbF+O4e59Rj1nRDM68YzBWPiU74aWeeiJMri3yPPUCq5kjmDsmk3/ZbWOm8DqkZWSxvmawklI5S9Xicmn/zDw8wfckSvimwaJjIY9mOOZZwfvfIGpZIkF2yk3fyoNde3XV+3OKR6qZGMy2aDKuj2P48keQ7aPTC1KJDZEvr7TCCQ+ke4/obgio2sGrYzm9WXtUMWqZaFWeJoVao8CsmXDyA+HeANFJqNF0gOnXImMaIdV13fUpTagelPt9b9CbVImF6qw570h1l9g5cUll7MSmqxTr7I7R76tsLWvqTqFLYVsWPgbVLgQqVW5uR/WqOX2i/c+tXBzViG/KiMXKi2wdv/uBf6fWqMFYH1u2fWfwHvV1q65O57fAn4G/Ep9XILJuD4AAAAASUVORK5CYII='); background-size: cover; display: block;\"></span>\n  <img class=\"gatsby-resp-image-image\" alt=\"Driver's Diversity vs. Number of Transfers\" title=\"Driver's Diversity vs. Number of Transfers\" src=\"/static/923470de9ad80e8aa947dfb3aed2af30/9e32a/heatsink_work3.png\" srcset=\"/static/923470de9ad80e8aa947dfb3aed2af30/12f09/heatsink_work3.png 148w,\n/static/923470de9ad80e8aa947dfb3aed2af30/e4a3f/heatsink_work3.png 295w,\n/static/923470de9ad80e8aa947dfb3aed2af30/9e32a/heatsink_work3.png 412w\" sizes=\"(max-width: 412px) 100vw, 412px\" style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\" loading=\"lazy\">\n  </a>\n    </span>\n</div>\n<p>By integrating non-blocking communication, we were able to further enhance the efficiency of our parallelized simulation. This technique allowed processors to continue computations while waiting for data exchanges, leading to improved execution times without compromising accuracy.</p>\n<p>Our results clearly demonstrate the effectiveness of parallelization in reducing simulation time, particularly with more complex slicing techniques and optimized communication strategies.</p>\n<h2>Watch the Video</h2>\n<p>You can watch the execution of the heat transfer simulation below. The video shows the temperature gradient between two key areas: the end of the heatsink connected to the CPU and the other end where heat is dissipated.</p>\n<div class=\"gatsby-resp-iframe-wrapper\" style=\"padding-bottom: 48.61111111111111%; position: relative; height: 0; overflow: hidden; margin-bottom: 1.0725rem\" > <iframe src=\"https://www.youtube.com/embed/a6JIAh20gbQ\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen=\"\" style=\" position: absolute; top: 0; left: 0; width: 100%; height: 100%; \"></iframe> </div>\n<hr>\n<p>If you’re interested in exploring the full methodology and results, you can download the complete paper <a href=\"/990fa1171bd01bfdd3421e5c40062f8c/paper.pdf\">here</a>.</p>","frontmatter":{"title":"Parallelization Strategies for Numerical Simulation of Heat Transfer in CPU Heatsinks","date":"November 23, 2023","description":"In this post, I share insights from my research on parallelizing simulations for CPU heatsink heat transfer. I explored two parallelization techniques—1D slicing along the Z-axis and 2D slicing along the Z and Y axes—to efficiently model heat dissipation in a 3D grid structure. By leveraging MPI for communication between processors and implementing non-blocking communication, I significantly improved performance, achieving up to 5.63x speedup with 32 processors. This study highlights the effectiveness of optimized computational strategies in reducing simulation time while maintaining accuracy."}}},"pageContext":{"slug":"/blog/my-first-blog/","previous":{"fields":{"slug":"/blog/my-third-blog/"},"frontmatter":{"title":"Ride-Hailing Trends in New York City ( Uber, Lyft, and Via ) Operations Analysis"}},"next":{"fields":{"slug":"/blog/my-second-blog/"},"frontmatter":{"title":"Enhancing Execution Speed of White Noise Generation through Parallelization and Vectorization"}}}},"staticQueryHashes":["63159454"]}